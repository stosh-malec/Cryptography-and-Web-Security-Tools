import re
import urllib.request
from bs4 import BeautifulSoup

  
def Spider(html_queue, all_links, recursion):
  url = input('Please enter targer URL')
  recursion = input('Please enter a number of appropriate links to recurse through')
  html_queue = []
  all_links = []
  html_queue.append(url)
  for x in range(0, int(recursion)):
    html = urllib.request.urlopen(html_queue[x])
    soup = BeautifulSoup(html)
    for link in soup.findAll('a', attrs={'href': re.compile("^http://")}):
      all_links.append(link.get('href'))
      if not link in html_queue:
        html_queue.append(link.get('href'))
  print(all_links, " are on the page  ", url, "with a depth of ", recursion)


#To contribute, add multithreading and add connection headers to change from default python requests headers
